{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General overview\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------\n",
    "The following Jupyter notebook was created in order to automate the process of generating and visualizing forecasts for the macroeconomic indicators using historical time series retrieved using World Bank's Indicators API. Forecast will be generated using Auto ARIMA library which uses ARIMA, SARIMA and SARIMAX models under the hood and selects the one which suits best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and set the display options\n",
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Data preprocessing libraries and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from retrieval_funcs import create_world_bank_api_url_string, retrieve_url_content\n",
    "from preprocessing_funcs import convert_bytes_to_unicode, extract_dates_and_values_from_json\n",
    "\n",
    "# Visualization function\n",
    "from plotting_funcs import plot_historical_and_forecasted_values\n",
    "\n",
    "# Modelling library\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# Set pandas data display options\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script parameters\n",
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color: #e60000; font-size:17px;\">Please provide the country and economic indicator codes for which you would like to generate the forecast as well as year up to which it should be done. Downloaded time series and forecasted values will be saved to an '.xlsx' file and stored in the 'output' folder.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY_CODE = 'ger'\n",
    "INDICATOR_CODE = 'EN.ATM.CO2E.PC'\n",
    "PREDICT_UP_TO_YEAR_INCLUSIVE = 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and preprocess data \n",
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-336d58ab6166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Extract indicator_name, dates and values from JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mindicator_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_dates_and_values_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create DataFrame object using dates and values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/PERSONAL/world_bank_data_forecasting/preprocessing_funcs.py\u001b[0m in \u001b[0;36mextract_dates_and_values_from_json\u001b[0;34m(json_data)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"json_data must be a list\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mindicator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'indicator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Create query string used to retrieve the data using World Bank's Indicators API\n",
    "query_string = create_world_bank_api_url_string(COUNTRY_CODE, INDICATOR_CODE)\n",
    "\n",
    "# Retrieve data \n",
    "data = retrieve_url_content(query_string)\n",
    "\n",
    "# Convert retrieved data represented as bytes object to JSON\n",
    "json_string = convert_bytes_to_unicode(data)\n",
    "json_content = json.loads(json_string)\n",
    "\n",
    "# Extract indicator_name, dates and values from JSON\n",
    "indicator_name, dates, values = extract_dates_and_values_from_json(json_content)\n",
    "\n",
    "# Create DataFrame object using dates and values\n",
    "time_series_df = pd.DataFrame.from_dict({\"Date\": dates,\n",
    "                                         \"Value\": values})\n",
    "\n",
    "# Set index to Date column and change its type to datetime \n",
    "time_series_df.set_index('Date', inplace=True)\n",
    "time_series_df.index = pd.to_datetime(time_series_df.index)\n",
    "\n",
    "# Sort DataFrame years ascendingly\n",
    "time_series_df.sort_values(by='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[{\"message\":[{\"id\":\"120\",\"key\":\"Invalid value\",\"value\":\"The provided parameter value is not valid\"}]}]'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to check if our time series has any missing values, and if so, deal with them.\n",
    "\n",
    "There are many approaches to missing data imputation, i.e. filling the missing values with mean or median (might do the job in time independent datasets), using rolling average, training other models on the remaining explanatory variables and using them to predict the values for the missing column (applicable to multivariate datasets and very time consuming) or using some kind of interpolation. In case of the univariate series retrieved from the World Bank, we will stick to some kind of interpolation as suggested in the below article:\n",
    "\n",
    "<b>https://medium.com/@drnesr/filling-gaps-of-a-time-series-using-python-d4bfddd8c460</b>\n",
    "\n",
    "Once we are done, we will apply the Auto ARIMA library to help us choose the best forecasting model to the given time series. This will make the script useful for other economic indicators as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of the first and last row with non-missing values\n",
    "first_non_missing_row = time_series_df.first_valid_index()\n",
    "last_non_missing_row = time_series_df.last_valid_index()\n",
    "\n",
    "# If series has any missing values, fill in the gaps using 'time' interpolation\n",
    "if time_series_df.isnull().sum().sum() > 0:\n",
    "    # Subselect all rows up until the last non-missing one, if missing rows are at the end\n",
    "    # of the time series, we will try to predict their values using Auto ARIMA model\n",
    "    # instead of using Interpolation\n",
    "    time_series_df = time_series_df[:last_non_missing_row]\n",
    "    time_series_df['InterpolatedValue'] = time_series_df['Value'].interpolate(method='time')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the interpolation results by displaying the data\n",
    "time_series_df.head(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Value' column as we will no longer need it\n",
    "time_series_df.drop('Value', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there are no missing values at the beginning of the time series - interpolation were not able\n",
    "# to impute values for them and Auto ARIMA will raise an error in case of missing data\n",
    "\n",
    "time_series_df = time_series_df[first_non_missing_row:]\n",
    "time_series_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with Auto ARIMA\n",
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Auto ARIMA library will speed up the forecasting process because the data preparation and parameter tuning processes for ARIMA, SARIMA and SARIMAX models end up being really time consuming. Auto ARIMA makes forecast preparation much simpler, because it:\n",
    "\n",
    "<ul>\n",
    "    <ul>\n",
    "        <li> Performs data stationarity checks\n",
    "        <li> Determines the <b>d</b> value which stands for the number of times the differencing operation has to be applied to the time series to make it stationary\n",
    "        <li> Handles hyperparameter selection for models, hence saves us from doing this manually by looking at the ACF and PACF plots\n",
    "        <li> Choses most accurate forecasting model for the given time series\n",
    "    </ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, in all Machine Learning related projects we need to divide the dataset into training and validation subsets to verify whether the model's 'accurate' predictions are not a result of memorizing the dataset on which it was trained. It's also a good practice to prepare a test(holdout) subset which is used to verify the accuracy of the final model(chosen out of many). This practice is oftentimes used for Econometric models like ARMA, ARIMA or SARIMA as well, however taking into consideration the size of this dataset and the fact that around 40% of values were missing and had to be imputed, we will proceed by training the model on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_arima(time_series_df['InterpolatedValue'],\n",
    "                   start_p=1,\n",
    "                   start_q=1,\n",
    "                   max_p=6,\n",
    "                   max_q=6,\n",
    "                   max_d=4,\n",
    "                   maxiter=100,\n",
    "                   max_order=None,\n",
    "                   # Stepwise algo is less likely to over-fit than Grid Search\n",
    "                   stepwise=True,\n",
    "                   trace=True,\n",
    "                   error_action='ignore',\n",
    "                   suppress_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast future values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of periods for which the forecast needs to be generated\n",
    "num_periods = PREDICT_UP_TO_YEAR_INCLUSIVE - last_non_missing_row.year\n",
    "\n",
    "# Generate forecasts\n",
    "forecast = model.predict(n_periods=num_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time series beginning year timestamp and convert forecast horizon end year to Timestamp object\n",
    "time_series_beginning = time_series_df.index[0]\n",
    "forecast_end = pd.Timestamp(datetime.strptime(str(PREDICT_UP_TO_YEAR_INCLUSIVE + 1), '%Y'))\n",
    "\n",
    "\n",
    "# Create DataFrame object storing historical and forecasted values\n",
    "combined_df = pd.DataFrame({'Date': pd.date_range(start = time_series_beginning,\n",
    "                                                  end=forecast_end,\n",
    "                                                  freq='Y'),\n",
    "                            'Value': time_series_df['InterpolatedValue'].tolist() + list(forecast)})\n",
    "\n",
    "# Add 'Type' column to DataFrame to distinguish historical and forecasted values\n",
    "combined_df['Type'] = ['historical' if i < len(time_series_df['InterpolatedValue'])\n",
    "                       else 'forecasted' for i in range(len(combined_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the country code to country name map from JSON file\n",
    "with open('country_code_to_name.json') as json_file:\n",
    "    code_to_name = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_excel(f'output/{INDICATOR_CODE}-{code_to_name[COUNTRY_CODE]}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot historical and forecasted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_historical_and_forecasted_values(combined_df,\n",
    "                                      x='Date',\n",
    "                                      y='Value',\n",
    "                                      color_by_col='Type',\n",
    "                                      indicator_code=INDICATOR_CODE,\n",
    "                                      indicator_name = indicator_name,\n",
    "                                      country=code_to_name[COUNTRY_CODE])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
